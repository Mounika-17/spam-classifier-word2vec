{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba73349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef03232",
   "metadata": {},
   "source": [
    "### Gensim\n",
    "1. It is a python library which provides a built-in models like  ready-to-use implementation of Word2Vec —you don’t have to build the neural network from scratch.\n",
    "2. We can try the already built-in models like Word2Vec, GloVe, or FastText using gensim.downloader.api.load()\n",
    "3. If we want to train our own embeddings we can do that - from gensim.models import Word2Vec\n",
    "4. There are different word2vec models. If we want to create our own embedding model we need to import the Word2Vec class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ad2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dd39ff",
   "metadata": {},
   "source": [
    "#### Let's see how we can load the google-news word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d998717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0c7667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156fe50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how the model give an output for a word\n",
    "# Google news word2vec model has 300 dimensions and it is trained on 3 million words/phrases. 300 dimensions means each word is represented as a vector of 300 elements.\n",
    "# Let's see the vector for the word 'king'\n",
    "vector = model['king']\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad99f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_length = len(vector)\n",
    "print(f\"Length of the vector for the word 'king': {vector_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692fec07",
   "metadata": {},
   "source": [
    "#### Let's create our own Word2Vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe456e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the data folder\n",
    "import pandas as pd\n",
    "file_path = os.path.join('..', 'data', 'SMSSpamCollection.txt')\n",
    "messages=pd.read_csv(file_path, sep='\\t', names=['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09ee748",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88e4e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets do the data cleaning and preprocessing\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e5971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prepares text for CountVectorizer or TfidfVectorizer, which expect string sentences, not token lists.\n",
    "# But for Word2Vec, we need list of token lists. That is done in the next cells.\n",
    "corpus=[]\n",
    "for i in range(0,len(messages)):\n",
    "    # [^a-zA-Z] → “anything not (^) an uppercase (A–Z) or lowercase (a–z) letter”.THis this removes all digits (0–9), punctuation, symbols, etc. Replace them with spaces from message column\n",
    "    # If we need numbers we can use [^a-zA-Z0-9]\n",
    "    review = re.sub('[^a-zA-Z]', ' ', messages['message'][i])\n",
    "    review = review.lower()\n",
    "    # Split the sentences in to words by spaces\n",
    "    review = review.split()\n",
    "    # Apply the stemming\n",
    "    review = [lemmatizer.lemmatize(word) for word in review]\n",
    "    # Join the words to make sentences\n",
    "    # If review is empty → ' '.join([]) → '' (an empty string).\n",
    "    review = ' '.join(review)\n",
    "    # Append the snetence to corpus\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e34970e",
   "metadata": {},
   "source": [
    "#### Meaning of the below list comprehensino\n",
    "| Expression          | Meaning                                                         |\n",
    "| ------------------- | --------------------------------------------------------------- |\n",
    "| `map(len, corpus)`  | Gets length of each cleaned message                             |\n",
    "| `zip(...)`          | Pairs lengths, cleaned messages, and original messages together |\n",
    "| `if i < 1`          | Filters messages with empty cleaned text                        |\n",
    "| `[ [i, j, k] ... ]` | Builds list showing length, cleaned text, and original text     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d27ea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see if there are any empty messages in the corpus. \n",
    "# This helps in identifying the messages became empty after cleaning (e.g., removing stopwords, punctuation, etc.)\n",
    "[[i,j,k] for i,j,k in zip(list(map(len,corpus)),corpus, messages['message']) if i<1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0048b749",
   "metadata": {},
   "source": [
    "#### empty strings '' can appear in corpus if the original message has no letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861197a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the complete details which original messages became empty after cleaning\n",
    "for i, j, k in zip(list(map(len, corpus)), corpus, messages['message']):\n",
    "    if i < 1:\n",
    "        print(f\"Original: {k}\")\n",
    "        print(f\"Cleaned: '{j}'\")\n",
    "        print(f\"Length: {i}\\n\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49647c8",
   "metadata": {},
   "source": [
    "#### The 3 empty strings with white spaces that are after cleaning of the corpus will not be considered in the words. So total size will be reduced from 5572 to 5569 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c994632f",
   "metadata": {},
   "source": [
    "##### How the below logic works?\n",
    "| Case    | Will it be added to `words`?                             | Reason                                        |\n",
    "| ------- | -------------------------------------------------------- | --------------------------------------------- |\n",
    "| `''`    | ❌ No                                                     | `sent_tokenize` → `[]`                        |\n",
    "| `'   '` | ❌ No (inner loop skips) or empty list if passed directly | No valid sentence/tokens                      |\n",
    "| `'u'`   | ✅ Added as `[]` by default (filtered)                    | Single char → filtered out unless `min_len=1` |\n",
    "| `'hi'`  | ✅ Added as `['hi']`                                      | Valid token                                   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1b4c7fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each cleaned sentence into a list of tokenized words for Word2Vec training.\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from gensim.utils import simple_preprocess\n",
    "# Words is the list of lists. It stores each sentence as a list of words and do it for all the sentences, for every sentence one list of words are created.\n",
    "words=[]\n",
    "for sent in corpus:\n",
    "    sent_token=sent_tokenize(sent)\n",
    "    for sent in sent_token:\n",
    "        words.append(simple_preprocess(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a6d46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cd9fdb",
   "metadata": {},
   "source": [
    "##### Below are the steps to check the empty strings in words list and why there is a difference in the length of corpus and length of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd186951",
   "metadata": {},
   "outputs": [],
   "source": [
    "any(len(w) == 0 for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a71d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count empties\n",
    "sum(len(w)==0 for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbabe845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the indexes of the empty words\n",
    "[i for i,w in enumerate(words) if len(w)==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b8ac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives the 3 empty strings with white spaces from the corpus which I mentioned previously.\n",
    "[i for i, x in enumerate(corpus) if x.strip() == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eac30766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5572\n",
      "5569\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus))\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d26970",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [4291, 5170]:\n",
    "    print(f\"Index {i}: {repr(corpus[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17725793",
   "metadata": {},
   "outputs": [],
   "source": [
    "words[4291]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58126e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "words[5170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7670a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When you skip empty sentences in your corpus → words loop (like if len(tokens) > 0),you are not preserving one-to-one alignment between corpus and words. \n",
    "# So if words[4291] and words[5170] are empty, that tells us: these indices in words do not correspond to the same indices in corpus anymore.\n",
    "# If you want to check which corpus entries created empty words,you must loop together like this:\n",
    "empty_indices = []\n",
    "for i, sent in enumerate(corpus):\n",
    "    sent_token = sent_tokenize(sent)\n",
    "    for s in sent_token:\n",
    "        tokens = simple_preprocess(s)\n",
    "        if len(tokens) == 0:\n",
    "            empty_indices.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e6c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc34aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [4293, 5173]:\n",
    "    print(f\"Index {i}: {repr(corpus[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f52d508",
   "metadata": {},
   "source": [
    "##### If you see in the above they are very short messages 'g w r' and 'u'. Each contains a one or a few single-letter “words”. \n",
    "What simple_preprocess() does:\n",
    "\n",
    "gensim.utils.simple_preprocess() is not just a basic split —\n",
    "1. it removes very short tokens by default.\n",
    "2. By design, it ignores tokens that:  \n",
    "\n",
    "Are shorter than 2 characters (default min_len=2)  \n",
    "\n",
    "Or longer than 15 characters (default max_len=15)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d017e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we get 5569 because 3 messages became empty after cleaning.\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1fe141b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's train our own Word2Vec model.\n",
    "import gensim\n",
    "# By default,min_count is 5, so words which are having frequency less than 5 will be ignored.\n",
    "# My model is trained on the words\n",
    "model=gensim.models.Word2Vec(words) # we can mention parameters like vector size, window size, min count etc. By default vector size is 100, window size is 5 and min count is 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311c4455",
   "metadata": {},
   "source": [
    "#### 🧩 1️⃣ “100 dimensions” — are those also the words in my vocabulary?\n",
    "1. ❌ No — the 100 dimensions are not words. They are number of numeric features that capture relationships (like gender, tense, topic, etc.)\n",
    "2. They are numerical features (latent semantic dimensions) that represent meaning or context of words — not actual words themselves.\n",
    "3. These 100 numbers don’t correspond to specific words.Instead, they describe abstract properties — like:\n",
    "\n",
    "a. masculine/feminine axis   \n",
    "b. royalty/commoner axis  \n",
    "c. age, emotion, topic, etc.  \n",
    "\n",
    "The model learns these patterns automatically while training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1721, 100)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It will give the count of the words in the vocabulary and their dimension(means no.of columns)\n",
    "# since we have not mentioned any parameters, by default vector size is 100. so number of columns is 100.\n",
    "model.wv.vectors.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c15e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get all the vocabulary words in the model\n",
    "# Since I mentioned min_count as 5, words which are having frequency less than 5 are ignored.\n",
    "model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9209e5b",
   "metadata": {},
   "source": [
    "#### 🧩 2️⃣ Should model.wv.vectors.shape and model.corpus_count be the same?\n",
    "❌ No, they are not the same thing — and they almost never match.\n",
    "| Attribute                   | Meaning                                                    |\n",
    "| --------------------------- | ---------------------------------------------------------- |\n",
    "| `model.wv.vectors.shape[0]` | Number of **unique words in the vocabulary** (rows)        |\n",
    "| `model.corpus_count`        | Number of **sentences** (or “documents”) used for training |\n",
    "\n",
    "🧠 Analogy\n",
    "\n",
    "Think of Word2Vec as a language school:  \n",
    "\n",
    "corpus_count → how many sentences it studied.  \n",
    "\n",
    "wv.vectors.shape[0] → how many unique words it learned from them.  \n",
    "\n",
    "wv.vectors.shape[1] → how many traits each word has learned (like tone, tense, meaning).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It indicates the number of sentences (or “documents”) used for training\n",
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.epochs means it tells how many times your Word2Vec model iterated over the entire training corpus during training\n",
    "model.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the similar words\n",
    "model.wv.most_similar('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['good'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f9b7da71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go',\n",
       " 'until',\n",
       " 'jurong',\n",
       " 'point',\n",
       " 'crazy',\n",
       " 'available',\n",
       " 'only',\n",
       " 'in',\n",
       " 'bugis',\n",
       " 'great',\n",
       " 'world',\n",
       " 'la',\n",
       " 'buffet',\n",
       " 'cine',\n",
       " 'there',\n",
       " 'got',\n",
       " 'amore',\n",
       " 'wat']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b071d2",
   "metadata": {},
   "source": [
    "##### What is model.wv in Word2Vec?\n",
    "| Part       | Description                                                             |\n",
    "| ---------- | ----------------------------------------------------------------------- |\n",
    "| `model.wv` | **Word vectors** — this is your vocabulary + learned embeddings         |\n",
    "| `model`    | Full model (includes training settings, negative sampling tables, etc.) |\n",
    "\n",
    "✅ So yes — model.wv is the learned vocabulary of your Word2Vec model.\n",
    "1. It stores all unique words that appeared in your training corpus (subject to min_count).\n",
    "2. It also stores the vector representation for each of those words.\n",
    "\n",
    "##### How we can get the NaNs?\n",
    "If a sentence has no valid words in model.wv, like \"12345\", \"!!!\", \"###\", etc.\n",
    "Then the list vectors becomes empty: vectors=[]  \n",
    "and   \n",
    "\n",
    "np.mean(vector,axis=0) returns nan.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "37cde0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have 100 dimesions for every word of word[0] similarly for all words in the words list.We need to take average of all word vectors to represent the entire sentence.\n",
    "# model.wv- \n",
    "import numpy as np\n",
    "def avg_word2vec(tokens,model):\n",
    "    # Iterates through each word in the sentence and retrieves its corresponding word vector from the Word2Vec model (model.wv).Collects these vectors into a list called vectors.\n",
    "    vectors=[model.wv[word] for word in tokens if word in model.wv]\n",
    "    if len(vectors)>0:\n",
    "       return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "       # Suppose if the words in the sentence are not present in the vocabulary of the model i.e model.wv, then the list vectors becomes empty and if we do np.mean(vectors, axis=0) it returns a Nan value. To avoid that we can return a zero vector of same dimension as the model's word vectors.\n",
    "       return np.zeros(model.vector_size) # Handle the case where no words are found in the model's vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f46fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb2dc7a",
   "metadata": {},
   "source": [
    "##### tqdm:\n",
    "tqdm is a python library for progress bars. It shows you a real-time progress indicator in the console or notebook while loops are running.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a019d40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e9201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5569/5569 [00:00<00:00, 17723.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Apply the avg_word2vec function to each sentence in the words list to get the average word vectors for all sentences.\n",
    "import numpy as np\n",
    "# X is a list of vectors\n",
    "X=[]\n",
    "for i in tqdm(range(len(words))):\n",
    "    X.append(avg_word2vec(words[i],model))\n",
    "# Converts X into a Numpy array\n",
    "# X is a list of vectors. Not compatible with ML models. so convert it into a 2D NumPy array.\n",
    "X=np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b06d7fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5569"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f312175d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9e498a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5569"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)  # number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "17a5f7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9da71bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= messages['label'].map({'ham': 0, 'spam': 1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c56ac5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056856e4",
   "metadata": {},
   "source": [
    "#### Execution of the below code:\n",
    "| Step | Expression                          | What It Does                                                    | Result Type  |\n",
    "| ---- | ----------------------------------- | --------------------------------------------------------------- | ------------ |\n",
    "| 1    | `map(lambda x: len(x) > 0, corpus)` | Checks which corpus entries are non-empty                       | list of bool |\n",
    "| 2    | `messages[...]`                     | Filters DataFrame to keep only rows with non-empty cleaned text | DataFrame    |\n",
    "| 3    | `y['label']`                        | Selects the label column                                        | Series       |\n",
    "| 4    | `.map({'ham': 0, 'spam': 1})`       | Converts text labels to numbers                                 | Series (int) |\n",
    "| 5    | `.values`                           | Converts Series → NumPy array                                   | ndarray      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861df2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y is considering all the sentences but after cleaning like applying the regular expression '[^a-zA-Z]' we got the total 5569 sentences lets add that filter to y.\n",
    "# messages is the dataframe with 2 columns message and label and y stores the updated dataframe  where the corresponding corpus entry was non-empty.\n",
    "y=messages[list(map(lambda x:len(x)>0, corpus))] # This selects only the rows where the corresponding corpus entry was non-empty.\n",
    "# From the filtered DataFrame y, we take the label column and replaces the string labels using a dictionary: 'ham' → 0 and 'spam' → 1\n",
    "# .values - this converts the pandas series to a numpy array.\n",
    "y= y['label'].map({'ham': 0, 'spam': 1}).values          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fa903b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5569"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "613e95f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5569,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8ef07f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5569, 100)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4b13814f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Final independent features\n",
    "# Convert the entire 2D array X into a DataFrame\n",
    "df = pd.DataFrame(X)\n",
    "print(df.isnull().sum().sum())  # should be 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "316531d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.184675</td>\n",
       "      <td>0.149868</td>\n",
       "      <td>0.089056</td>\n",
       "      <td>0.094514</td>\n",
       "      <td>0.090070</td>\n",
       "      <td>-0.514925</td>\n",
       "      <td>0.145919</td>\n",
       "      <td>0.472682</td>\n",
       "      <td>-0.259969</td>\n",
       "      <td>-0.115657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329387</td>\n",
       "      <td>0.161341</td>\n",
       "      <td>0.075355</td>\n",
       "      <td>0.020196</td>\n",
       "      <td>0.444074</td>\n",
       "      <td>0.183508</td>\n",
       "      <td>0.185545</td>\n",
       "      <td>-0.169584</td>\n",
       "      <td>0.147358</td>\n",
       "      <td>0.017244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.170940</td>\n",
       "      <td>0.132376</td>\n",
       "      <td>0.075826</td>\n",
       "      <td>0.081203</td>\n",
       "      <td>0.084306</td>\n",
       "      <td>-0.449808</td>\n",
       "      <td>0.116743</td>\n",
       "      <td>0.418098</td>\n",
       "      <td>-0.227575</td>\n",
       "      <td>-0.095866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293413</td>\n",
       "      <td>0.133892</td>\n",
       "      <td>0.060903</td>\n",
       "      <td>0.010904</td>\n",
       "      <td>0.376821</td>\n",
       "      <td>0.155787</td>\n",
       "      <td>0.162528</td>\n",
       "      <td>-0.157472</td>\n",
       "      <td>0.136299</td>\n",
       "      <td>0.008651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.196712</td>\n",
       "      <td>0.162979</td>\n",
       "      <td>0.097607</td>\n",
       "      <td>0.114731</td>\n",
       "      <td>0.072596</td>\n",
       "      <td>-0.549484</td>\n",
       "      <td>0.144973</td>\n",
       "      <td>0.468559</td>\n",
       "      <td>-0.273950</td>\n",
       "      <td>-0.140274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324815</td>\n",
       "      <td>0.165711</td>\n",
       "      <td>0.076328</td>\n",
       "      <td>0.008008</td>\n",
       "      <td>0.459194</td>\n",
       "      <td>0.167880</td>\n",
       "      <td>0.138783</td>\n",
       "      <td>-0.200509</td>\n",
       "      <td>0.176054</td>\n",
       "      <td>0.031851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.253898</td>\n",
       "      <td>0.202698</td>\n",
       "      <td>0.116573</td>\n",
       "      <td>0.127540</td>\n",
       "      <td>0.123346</td>\n",
       "      <td>-0.701212</td>\n",
       "      <td>0.194435</td>\n",
       "      <td>0.650995</td>\n",
       "      <td>-0.357901</td>\n",
       "      <td>-0.150240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450066</td>\n",
       "      <td>0.215079</td>\n",
       "      <td>0.098566</td>\n",
       "      <td>0.032351</td>\n",
       "      <td>0.593383</td>\n",
       "      <td>0.255118</td>\n",
       "      <td>0.269659</td>\n",
       "      <td>-0.231937</td>\n",
       "      <td>0.202422</td>\n",
       "      <td>0.013255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.217036</td>\n",
       "      <td>0.161471</td>\n",
       "      <td>0.106043</td>\n",
       "      <td>0.102467</td>\n",
       "      <td>0.113860</td>\n",
       "      <td>-0.591734</td>\n",
       "      <td>0.160089</td>\n",
       "      <td>0.549833</td>\n",
       "      <td>-0.304921</td>\n",
       "      <td>-0.132945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382365</td>\n",
       "      <td>0.179177</td>\n",
       "      <td>0.084932</td>\n",
       "      <td>0.030410</td>\n",
       "      <td>0.499131</td>\n",
       "      <td>0.216194</td>\n",
       "      <td>0.220312</td>\n",
       "      <td>-0.203990</td>\n",
       "      <td>0.161932</td>\n",
       "      <td>0.009948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.184675  0.149868  0.089056  0.094514  0.090070 -0.514925  0.145919   \n",
       "1 -0.170940  0.132376  0.075826  0.081203  0.084306 -0.449808  0.116743   \n",
       "2 -0.196712  0.162979  0.097607  0.114731  0.072596 -0.549484  0.144973   \n",
       "3 -0.253898  0.202698  0.116573  0.127540  0.123346 -0.701212  0.194435   \n",
       "4 -0.217036  0.161471  0.106043  0.102467  0.113860 -0.591734  0.160089   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0  0.472682 -0.259969 -0.115657  ...  0.329387  0.161341  0.075355  0.020196   \n",
       "1  0.418098 -0.227575 -0.095866  ...  0.293413  0.133892  0.060903  0.010904   \n",
       "2  0.468559 -0.273950 -0.140274  ...  0.324815  0.165711  0.076328  0.008008   \n",
       "3  0.650995 -0.357901 -0.150240  ...  0.450066  0.215079  0.098566  0.032351   \n",
       "4  0.549833 -0.304921 -0.132945  ...  0.382365  0.179177  0.084932  0.030410   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0  0.444074  0.183508  0.185545 -0.169584  0.147358  0.017244  \n",
       "1  0.376821  0.155787  0.162528 -0.157472  0.136299  0.008651  \n",
       "2  0.459194  0.167880  0.138783 -0.200509  0.176054  0.031851  \n",
       "3  0.593383  0.255118  0.269659 -0.231937  0.202422  0.013255  \n",
       "4  0.499131  0.216194  0.220312 -0.203990  0.161932  0.009948  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e686f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Output']=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "47e0ee34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.184675</td>\n",
       "      <td>0.149868</td>\n",
       "      <td>0.089056</td>\n",
       "      <td>0.094514</td>\n",
       "      <td>0.090070</td>\n",
       "      <td>-0.514925</td>\n",
       "      <td>0.145919</td>\n",
       "      <td>0.472682</td>\n",
       "      <td>-0.259969</td>\n",
       "      <td>-0.115657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161341</td>\n",
       "      <td>0.075355</td>\n",
       "      <td>0.020196</td>\n",
       "      <td>0.444074</td>\n",
       "      <td>0.183508</td>\n",
       "      <td>0.185545</td>\n",
       "      <td>-0.169584</td>\n",
       "      <td>0.147358</td>\n",
       "      <td>0.017244</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.170940</td>\n",
       "      <td>0.132376</td>\n",
       "      <td>0.075826</td>\n",
       "      <td>0.081203</td>\n",
       "      <td>0.084306</td>\n",
       "      <td>-0.449808</td>\n",
       "      <td>0.116743</td>\n",
       "      <td>0.418098</td>\n",
       "      <td>-0.227575</td>\n",
       "      <td>-0.095866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133892</td>\n",
       "      <td>0.060903</td>\n",
       "      <td>0.010904</td>\n",
       "      <td>0.376821</td>\n",
       "      <td>0.155787</td>\n",
       "      <td>0.162528</td>\n",
       "      <td>-0.157472</td>\n",
       "      <td>0.136299</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.196712</td>\n",
       "      <td>0.162979</td>\n",
       "      <td>0.097607</td>\n",
       "      <td>0.114731</td>\n",
       "      <td>0.072596</td>\n",
       "      <td>-0.549484</td>\n",
       "      <td>0.144973</td>\n",
       "      <td>0.468559</td>\n",
       "      <td>-0.273950</td>\n",
       "      <td>-0.140274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165711</td>\n",
       "      <td>0.076328</td>\n",
       "      <td>0.008008</td>\n",
       "      <td>0.459194</td>\n",
       "      <td>0.167880</td>\n",
       "      <td>0.138783</td>\n",
       "      <td>-0.200509</td>\n",
       "      <td>0.176054</td>\n",
       "      <td>0.031851</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.253898</td>\n",
       "      <td>0.202698</td>\n",
       "      <td>0.116573</td>\n",
       "      <td>0.127540</td>\n",
       "      <td>0.123346</td>\n",
       "      <td>-0.701212</td>\n",
       "      <td>0.194435</td>\n",
       "      <td>0.650995</td>\n",
       "      <td>-0.357901</td>\n",
       "      <td>-0.150240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215079</td>\n",
       "      <td>0.098566</td>\n",
       "      <td>0.032351</td>\n",
       "      <td>0.593383</td>\n",
       "      <td>0.255118</td>\n",
       "      <td>0.269659</td>\n",
       "      <td>-0.231937</td>\n",
       "      <td>0.202422</td>\n",
       "      <td>0.013255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.217036</td>\n",
       "      <td>0.161471</td>\n",
       "      <td>0.106043</td>\n",
       "      <td>0.102467</td>\n",
       "      <td>0.113860</td>\n",
       "      <td>-0.591734</td>\n",
       "      <td>0.160089</td>\n",
       "      <td>0.549833</td>\n",
       "      <td>-0.304921</td>\n",
       "      <td>-0.132945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179177</td>\n",
       "      <td>0.084932</td>\n",
       "      <td>0.030410</td>\n",
       "      <td>0.499131</td>\n",
       "      <td>0.216194</td>\n",
       "      <td>0.220312</td>\n",
       "      <td>-0.203990</td>\n",
       "      <td>0.161932</td>\n",
       "      <td>0.009948</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.184675  0.149868  0.089056  0.094514  0.090070 -0.514925  0.145919   \n",
       "1 -0.170940  0.132376  0.075826  0.081203  0.084306 -0.449808  0.116743   \n",
       "2 -0.196712  0.162979  0.097607  0.114731  0.072596 -0.549484  0.144973   \n",
       "3 -0.253898  0.202698  0.116573  0.127540  0.123346 -0.701212  0.194435   \n",
       "4 -0.217036  0.161471  0.106043  0.102467  0.113860 -0.591734  0.160089   \n",
       "\n",
       "          7         8         9  ...        91        92        93        94  \\\n",
       "0  0.472682 -0.259969 -0.115657  ...  0.161341  0.075355  0.020196  0.444074   \n",
       "1  0.418098 -0.227575 -0.095866  ...  0.133892  0.060903  0.010904  0.376821   \n",
       "2  0.468559 -0.273950 -0.140274  ...  0.165711  0.076328  0.008008  0.459194   \n",
       "3  0.650995 -0.357901 -0.150240  ...  0.215079  0.098566  0.032351  0.593383   \n",
       "4  0.549833 -0.304921 -0.132945  ...  0.179177  0.084932  0.030410  0.499131   \n",
       "\n",
       "         95        96        97        98        99  Output  \n",
       "0  0.183508  0.185545 -0.169584  0.147358  0.017244       0  \n",
       "1  0.155787  0.162528 -0.157472  0.136299  0.008651       0  \n",
       "2  0.167880  0.138783 -0.200509  0.176054  0.031851       1  \n",
       "3  0.255118  0.269659 -0.231937  0.202422  0.013255       0  \n",
       "4  0.216194  0.220312 -0.203990  0.161932  0.009948       0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "437aa1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INdependent feature\n",
    "# axis=1 → tells pandas to drop a column (instead of a row)\n",
    "X=df.drop('Output', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2376782a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.184675</td>\n",
       "      <td>0.149868</td>\n",
       "      <td>0.089056</td>\n",
       "      <td>0.094514</td>\n",
       "      <td>0.090070</td>\n",
       "      <td>-0.514925</td>\n",
       "      <td>0.145919</td>\n",
       "      <td>0.472682</td>\n",
       "      <td>-0.259969</td>\n",
       "      <td>-0.115657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329387</td>\n",
       "      <td>0.161341</td>\n",
       "      <td>0.075355</td>\n",
       "      <td>0.020196</td>\n",
       "      <td>0.444074</td>\n",
       "      <td>0.183508</td>\n",
       "      <td>0.185545</td>\n",
       "      <td>-0.169584</td>\n",
       "      <td>0.147358</td>\n",
       "      <td>0.017244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.170940</td>\n",
       "      <td>0.132376</td>\n",
       "      <td>0.075826</td>\n",
       "      <td>0.081203</td>\n",
       "      <td>0.084306</td>\n",
       "      <td>-0.449808</td>\n",
       "      <td>0.116743</td>\n",
       "      <td>0.418098</td>\n",
       "      <td>-0.227575</td>\n",
       "      <td>-0.095866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293413</td>\n",
       "      <td>0.133892</td>\n",
       "      <td>0.060903</td>\n",
       "      <td>0.010904</td>\n",
       "      <td>0.376821</td>\n",
       "      <td>0.155787</td>\n",
       "      <td>0.162528</td>\n",
       "      <td>-0.157472</td>\n",
       "      <td>0.136299</td>\n",
       "      <td>0.008651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.196712</td>\n",
       "      <td>0.162979</td>\n",
       "      <td>0.097607</td>\n",
       "      <td>0.114731</td>\n",
       "      <td>0.072596</td>\n",
       "      <td>-0.549484</td>\n",
       "      <td>0.144973</td>\n",
       "      <td>0.468559</td>\n",
       "      <td>-0.273950</td>\n",
       "      <td>-0.140274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324815</td>\n",
       "      <td>0.165711</td>\n",
       "      <td>0.076328</td>\n",
       "      <td>0.008008</td>\n",
       "      <td>0.459194</td>\n",
       "      <td>0.167880</td>\n",
       "      <td>0.138783</td>\n",
       "      <td>-0.200509</td>\n",
       "      <td>0.176054</td>\n",
       "      <td>0.031851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.253898</td>\n",
       "      <td>0.202698</td>\n",
       "      <td>0.116573</td>\n",
       "      <td>0.127540</td>\n",
       "      <td>0.123346</td>\n",
       "      <td>-0.701212</td>\n",
       "      <td>0.194435</td>\n",
       "      <td>0.650995</td>\n",
       "      <td>-0.357901</td>\n",
       "      <td>-0.150240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450066</td>\n",
       "      <td>0.215079</td>\n",
       "      <td>0.098566</td>\n",
       "      <td>0.032351</td>\n",
       "      <td>0.593383</td>\n",
       "      <td>0.255118</td>\n",
       "      <td>0.269659</td>\n",
       "      <td>-0.231937</td>\n",
       "      <td>0.202422</td>\n",
       "      <td>0.013255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.217036</td>\n",
       "      <td>0.161471</td>\n",
       "      <td>0.106043</td>\n",
       "      <td>0.102467</td>\n",
       "      <td>0.113860</td>\n",
       "      <td>-0.591734</td>\n",
       "      <td>0.160089</td>\n",
       "      <td>0.549833</td>\n",
       "      <td>-0.304921</td>\n",
       "      <td>-0.132945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382365</td>\n",
       "      <td>0.179177</td>\n",
       "      <td>0.084932</td>\n",
       "      <td>0.030410</td>\n",
       "      <td>0.499131</td>\n",
       "      <td>0.216194</td>\n",
       "      <td>0.220312</td>\n",
       "      <td>-0.203990</td>\n",
       "      <td>0.161932</td>\n",
       "      <td>0.009948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>-0.223848</td>\n",
       "      <td>0.192581</td>\n",
       "      <td>0.124638</td>\n",
       "      <td>0.131275</td>\n",
       "      <td>0.095183</td>\n",
       "      <td>-0.619041</td>\n",
       "      <td>0.178100</td>\n",
       "      <td>0.550970</td>\n",
       "      <td>-0.315842</td>\n",
       "      <td>-0.151573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387403</td>\n",
       "      <td>0.196807</td>\n",
       "      <td>0.099445</td>\n",
       "      <td>0.013497</td>\n",
       "      <td>0.541170</td>\n",
       "      <td>0.199318</td>\n",
       "      <td>0.181446</td>\n",
       "      <td>-0.214891</td>\n",
       "      <td>0.190730</td>\n",
       "      <td>0.037260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>-0.225151</td>\n",
       "      <td>0.173134</td>\n",
       "      <td>0.104921</td>\n",
       "      <td>0.117431</td>\n",
       "      <td>0.109292</td>\n",
       "      <td>-0.618269</td>\n",
       "      <td>0.171146</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>-0.327013</td>\n",
       "      <td>-0.136646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399320</td>\n",
       "      <td>0.196687</td>\n",
       "      <td>0.074456</td>\n",
       "      <td>0.019759</td>\n",
       "      <td>0.520700</td>\n",
       "      <td>0.212317</td>\n",
       "      <td>0.205315</td>\n",
       "      <td>-0.222403</td>\n",
       "      <td>0.182648</td>\n",
       "      <td>0.023028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>-0.251484</td>\n",
       "      <td>0.201482</td>\n",
       "      <td>0.112697</td>\n",
       "      <td>0.115808</td>\n",
       "      <td>0.112633</td>\n",
       "      <td>-0.681657</td>\n",
       "      <td>0.193501</td>\n",
       "      <td>0.634659</td>\n",
       "      <td>-0.345379</td>\n",
       "      <td>-0.158240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440722</td>\n",
       "      <td>0.224199</td>\n",
       "      <td>0.105644</td>\n",
       "      <td>0.038959</td>\n",
       "      <td>0.591623</td>\n",
       "      <td>0.254272</td>\n",
       "      <td>0.264226</td>\n",
       "      <td>-0.215579</td>\n",
       "      <td>0.187010</td>\n",
       "      <td>0.016739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>-0.227057</td>\n",
       "      <td>0.179454</td>\n",
       "      <td>0.107558</td>\n",
       "      <td>0.113808</td>\n",
       "      <td>0.103727</td>\n",
       "      <td>-0.625560</td>\n",
       "      <td>0.171240</td>\n",
       "      <td>0.572667</td>\n",
       "      <td>-0.315513</td>\n",
       "      <td>-0.147044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393685</td>\n",
       "      <td>0.196317</td>\n",
       "      <td>0.097647</td>\n",
       "      <td>0.030170</td>\n",
       "      <td>0.536607</td>\n",
       "      <td>0.224867</td>\n",
       "      <td>0.220657</td>\n",
       "      <td>-0.205249</td>\n",
       "      <td>0.172123</td>\n",
       "      <td>0.013329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>-0.253042</td>\n",
       "      <td>0.185922</td>\n",
       "      <td>0.118316</td>\n",
       "      <td>0.122309</td>\n",
       "      <td>0.118154</td>\n",
       "      <td>-0.676593</td>\n",
       "      <td>0.179707</td>\n",
       "      <td>0.616300</td>\n",
       "      <td>-0.341177</td>\n",
       "      <td>-0.159018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422967</td>\n",
       "      <td>0.204916</td>\n",
       "      <td>0.098151</td>\n",
       "      <td>0.026075</td>\n",
       "      <td>0.570765</td>\n",
       "      <td>0.246088</td>\n",
       "      <td>0.236648</td>\n",
       "      <td>-0.231370</td>\n",
       "      <td>0.184963</td>\n",
       "      <td>0.015346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5569 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0    -0.184675  0.149868  0.089056  0.094514  0.090070 -0.514925  0.145919   \n",
       "1    -0.170940  0.132376  0.075826  0.081203  0.084306 -0.449808  0.116743   \n",
       "2    -0.196712  0.162979  0.097607  0.114731  0.072596 -0.549484  0.144973   \n",
       "3    -0.253898  0.202698  0.116573  0.127540  0.123346 -0.701212  0.194435   \n",
       "4    -0.217036  0.161471  0.106043  0.102467  0.113860 -0.591734  0.160089   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5564 -0.223848  0.192581  0.124638  0.131275  0.095183 -0.619041  0.178100   \n",
       "5565 -0.225151  0.173134  0.104921  0.117431  0.109292 -0.618269  0.171146   \n",
       "5566 -0.251484  0.201482  0.112697  0.115808  0.112633 -0.681657  0.193501   \n",
       "5567 -0.227057  0.179454  0.107558  0.113808  0.103727 -0.625560  0.171240   \n",
       "5568 -0.253042  0.185922  0.118316  0.122309  0.118154 -0.676593  0.179707   \n",
       "\n",
       "            7         8         9   ...        90        91        92  \\\n",
       "0     0.472682 -0.259969 -0.115657  ...  0.329387  0.161341  0.075355   \n",
       "1     0.418098 -0.227575 -0.095866  ...  0.293413  0.133892  0.060903   \n",
       "2     0.468559 -0.273950 -0.140274  ...  0.324815  0.165711  0.076328   \n",
       "3     0.650995 -0.357901 -0.150240  ...  0.450066  0.215079  0.098566   \n",
       "4     0.549833 -0.304921 -0.132945  ...  0.382365  0.179177  0.084932   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5564  0.550970 -0.315842 -0.151573  ...  0.387403  0.196807  0.099445   \n",
       "5565  0.563637 -0.327013 -0.136646  ...  0.399320  0.196687  0.074456   \n",
       "5566  0.634659 -0.345379 -0.158240  ...  0.440722  0.224199  0.105644   \n",
       "5567  0.572667 -0.315513 -0.147044  ...  0.393685  0.196317  0.097647   \n",
       "5568  0.616300 -0.341177 -0.159018  ...  0.422967  0.204916  0.098151   \n",
       "\n",
       "            93        94        95        96        97        98        99  \n",
       "0     0.020196  0.444074  0.183508  0.185545 -0.169584  0.147358  0.017244  \n",
       "1     0.010904  0.376821  0.155787  0.162528 -0.157472  0.136299  0.008651  \n",
       "2     0.008008  0.459194  0.167880  0.138783 -0.200509  0.176054  0.031851  \n",
       "3     0.032351  0.593383  0.255118  0.269659 -0.231937  0.202422  0.013255  \n",
       "4     0.030410  0.499131  0.216194  0.220312 -0.203990  0.161932  0.009948  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5564  0.013497  0.541170  0.199318  0.181446 -0.214891  0.190730  0.037260  \n",
       "5565  0.019759  0.520700  0.212317  0.205315 -0.222403  0.182648  0.023028  \n",
       "5566  0.038959  0.591623  0.254272  0.264226 -0.215579  0.187010  0.016739  \n",
       "5567  0.030170  0.536607  0.224867  0.220657 -0.205249  0.172123  0.013329  \n",
       "5568  0.026075  0.570765  0.246088  0.236648 -0.231370  0.184963  0.015346  \n",
       "\n",
       "[5569 rows x 100 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d01a745d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.184675</td>\n",
       "      <td>0.149868</td>\n",
       "      <td>0.089056</td>\n",
       "      <td>0.094514</td>\n",
       "      <td>0.090070</td>\n",
       "      <td>-0.514925</td>\n",
       "      <td>0.145919</td>\n",
       "      <td>0.472682</td>\n",
       "      <td>-0.259969</td>\n",
       "      <td>-0.115657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161341</td>\n",
       "      <td>0.075355</td>\n",
       "      <td>0.020196</td>\n",
       "      <td>0.444074</td>\n",
       "      <td>0.183508</td>\n",
       "      <td>0.185545</td>\n",
       "      <td>-0.169584</td>\n",
       "      <td>0.147358</td>\n",
       "      <td>0.017244</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.170940</td>\n",
       "      <td>0.132376</td>\n",
       "      <td>0.075826</td>\n",
       "      <td>0.081203</td>\n",
       "      <td>0.084306</td>\n",
       "      <td>-0.449808</td>\n",
       "      <td>0.116743</td>\n",
       "      <td>0.418098</td>\n",
       "      <td>-0.227575</td>\n",
       "      <td>-0.095866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133892</td>\n",
       "      <td>0.060903</td>\n",
       "      <td>0.010904</td>\n",
       "      <td>0.376821</td>\n",
       "      <td>0.155787</td>\n",
       "      <td>0.162528</td>\n",
       "      <td>-0.157472</td>\n",
       "      <td>0.136299</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.196712</td>\n",
       "      <td>0.162979</td>\n",
       "      <td>0.097607</td>\n",
       "      <td>0.114731</td>\n",
       "      <td>0.072596</td>\n",
       "      <td>-0.549484</td>\n",
       "      <td>0.144973</td>\n",
       "      <td>0.468559</td>\n",
       "      <td>-0.273950</td>\n",
       "      <td>-0.140274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165711</td>\n",
       "      <td>0.076328</td>\n",
       "      <td>0.008008</td>\n",
       "      <td>0.459194</td>\n",
       "      <td>0.167880</td>\n",
       "      <td>0.138783</td>\n",
       "      <td>-0.200509</td>\n",
       "      <td>0.176054</td>\n",
       "      <td>0.031851</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.253898</td>\n",
       "      <td>0.202698</td>\n",
       "      <td>0.116573</td>\n",
       "      <td>0.127540</td>\n",
       "      <td>0.123346</td>\n",
       "      <td>-0.701212</td>\n",
       "      <td>0.194435</td>\n",
       "      <td>0.650995</td>\n",
       "      <td>-0.357901</td>\n",
       "      <td>-0.150240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215079</td>\n",
       "      <td>0.098566</td>\n",
       "      <td>0.032351</td>\n",
       "      <td>0.593383</td>\n",
       "      <td>0.255118</td>\n",
       "      <td>0.269659</td>\n",
       "      <td>-0.231937</td>\n",
       "      <td>0.202422</td>\n",
       "      <td>0.013255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.217036</td>\n",
       "      <td>0.161471</td>\n",
       "      <td>0.106043</td>\n",
       "      <td>0.102467</td>\n",
       "      <td>0.113860</td>\n",
       "      <td>-0.591734</td>\n",
       "      <td>0.160089</td>\n",
       "      <td>0.549833</td>\n",
       "      <td>-0.304921</td>\n",
       "      <td>-0.132945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179177</td>\n",
       "      <td>0.084932</td>\n",
       "      <td>0.030410</td>\n",
       "      <td>0.499131</td>\n",
       "      <td>0.216194</td>\n",
       "      <td>0.220312</td>\n",
       "      <td>-0.203990</td>\n",
       "      <td>0.161932</td>\n",
       "      <td>0.009948</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>-0.223848</td>\n",
       "      <td>0.192581</td>\n",
       "      <td>0.124638</td>\n",
       "      <td>0.131275</td>\n",
       "      <td>0.095183</td>\n",
       "      <td>-0.619041</td>\n",
       "      <td>0.178100</td>\n",
       "      <td>0.550970</td>\n",
       "      <td>-0.315842</td>\n",
       "      <td>-0.151573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196807</td>\n",
       "      <td>0.099445</td>\n",
       "      <td>0.013497</td>\n",
       "      <td>0.541170</td>\n",
       "      <td>0.199318</td>\n",
       "      <td>0.181446</td>\n",
       "      <td>-0.214891</td>\n",
       "      <td>0.190730</td>\n",
       "      <td>0.037260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>-0.225151</td>\n",
       "      <td>0.173134</td>\n",
       "      <td>0.104921</td>\n",
       "      <td>0.117431</td>\n",
       "      <td>0.109292</td>\n",
       "      <td>-0.618269</td>\n",
       "      <td>0.171146</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>-0.327013</td>\n",
       "      <td>-0.136646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196687</td>\n",
       "      <td>0.074456</td>\n",
       "      <td>0.019759</td>\n",
       "      <td>0.520700</td>\n",
       "      <td>0.212317</td>\n",
       "      <td>0.205315</td>\n",
       "      <td>-0.222403</td>\n",
       "      <td>0.182648</td>\n",
       "      <td>0.023028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>-0.251484</td>\n",
       "      <td>0.201482</td>\n",
       "      <td>0.112697</td>\n",
       "      <td>0.115808</td>\n",
       "      <td>0.112633</td>\n",
       "      <td>-0.681657</td>\n",
       "      <td>0.193501</td>\n",
       "      <td>0.634659</td>\n",
       "      <td>-0.345379</td>\n",
       "      <td>-0.158240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224199</td>\n",
       "      <td>0.105644</td>\n",
       "      <td>0.038959</td>\n",
       "      <td>0.591623</td>\n",
       "      <td>0.254272</td>\n",
       "      <td>0.264226</td>\n",
       "      <td>-0.215579</td>\n",
       "      <td>0.187010</td>\n",
       "      <td>0.016739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>-0.227057</td>\n",
       "      <td>0.179454</td>\n",
       "      <td>0.107558</td>\n",
       "      <td>0.113808</td>\n",
       "      <td>0.103727</td>\n",
       "      <td>-0.625560</td>\n",
       "      <td>0.171240</td>\n",
       "      <td>0.572667</td>\n",
       "      <td>-0.315513</td>\n",
       "      <td>-0.147044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196317</td>\n",
       "      <td>0.097647</td>\n",
       "      <td>0.030170</td>\n",
       "      <td>0.536607</td>\n",
       "      <td>0.224867</td>\n",
       "      <td>0.220657</td>\n",
       "      <td>-0.205249</td>\n",
       "      <td>0.172123</td>\n",
       "      <td>0.013329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>-0.253042</td>\n",
       "      <td>0.185922</td>\n",
       "      <td>0.118316</td>\n",
       "      <td>0.122309</td>\n",
       "      <td>0.118154</td>\n",
       "      <td>-0.676593</td>\n",
       "      <td>0.179707</td>\n",
       "      <td>0.616300</td>\n",
       "      <td>-0.341177</td>\n",
       "      <td>-0.159018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204916</td>\n",
       "      <td>0.098151</td>\n",
       "      <td>0.026075</td>\n",
       "      <td>0.570765</td>\n",
       "      <td>0.246088</td>\n",
       "      <td>0.236648</td>\n",
       "      <td>-0.231370</td>\n",
       "      <td>0.184963</td>\n",
       "      <td>0.015346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5569 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -0.184675  0.149868  0.089056  0.094514  0.090070 -0.514925  0.145919   \n",
       "1    -0.170940  0.132376  0.075826  0.081203  0.084306 -0.449808  0.116743   \n",
       "2    -0.196712  0.162979  0.097607  0.114731  0.072596 -0.549484  0.144973   \n",
       "3    -0.253898  0.202698  0.116573  0.127540  0.123346 -0.701212  0.194435   \n",
       "4    -0.217036  0.161471  0.106043  0.102467  0.113860 -0.591734  0.160089   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5564 -0.223848  0.192581  0.124638  0.131275  0.095183 -0.619041  0.178100   \n",
       "5565 -0.225151  0.173134  0.104921  0.117431  0.109292 -0.618269  0.171146   \n",
       "5566 -0.251484  0.201482  0.112697  0.115808  0.112633 -0.681657  0.193501   \n",
       "5567 -0.227057  0.179454  0.107558  0.113808  0.103727 -0.625560  0.171240   \n",
       "5568 -0.253042  0.185922  0.118316  0.122309  0.118154 -0.676593  0.179707   \n",
       "\n",
       "             7         8         9  ...        91        92        93  \\\n",
       "0     0.472682 -0.259969 -0.115657  ...  0.161341  0.075355  0.020196   \n",
       "1     0.418098 -0.227575 -0.095866  ...  0.133892  0.060903  0.010904   \n",
       "2     0.468559 -0.273950 -0.140274  ...  0.165711  0.076328  0.008008   \n",
       "3     0.650995 -0.357901 -0.150240  ...  0.215079  0.098566  0.032351   \n",
       "4     0.549833 -0.304921 -0.132945  ...  0.179177  0.084932  0.030410   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5564  0.550970 -0.315842 -0.151573  ...  0.196807  0.099445  0.013497   \n",
       "5565  0.563637 -0.327013 -0.136646  ...  0.196687  0.074456  0.019759   \n",
       "5566  0.634659 -0.345379 -0.158240  ...  0.224199  0.105644  0.038959   \n",
       "5567  0.572667 -0.315513 -0.147044  ...  0.196317  0.097647  0.030170   \n",
       "5568  0.616300 -0.341177 -0.159018  ...  0.204916  0.098151  0.026075   \n",
       "\n",
       "            94        95        96        97        98        99  Output  \n",
       "0     0.444074  0.183508  0.185545 -0.169584  0.147358  0.017244       0  \n",
       "1     0.376821  0.155787  0.162528 -0.157472  0.136299  0.008651       0  \n",
       "2     0.459194  0.167880  0.138783 -0.200509  0.176054  0.031851       1  \n",
       "3     0.593383  0.255118  0.269659 -0.231937  0.202422  0.013255       0  \n",
       "4     0.499131  0.216194  0.220312 -0.203990  0.161932  0.009948       0  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "5564  0.541170  0.199318  0.181446 -0.214891  0.190730  0.037260       1  \n",
       "5565  0.520700  0.212317  0.205315 -0.222403  0.182648  0.023028       0  \n",
       "5566  0.591623  0.254272  0.264226 -0.215579  0.187010  0.016739       0  \n",
       "5567  0.536607  0.224867  0.220657 -0.205249  0.172123  0.013329       0  \n",
       "5568  0.570765  0.246088  0.236648 -0.231370  0.184963  0.015346       0  \n",
       "\n",
       "[5569 rows x 101 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "95640f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "21be4a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8a76051b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4869</th>\n",
       "      <td>-0.221435</td>\n",
       "      <td>0.147823</td>\n",
       "      <td>0.100683</td>\n",
       "      <td>0.074971</td>\n",
       "      <td>0.131486</td>\n",
       "      <td>-0.566019</td>\n",
       "      <td>0.141018</td>\n",
       "      <td>0.539932</td>\n",
       "      <td>-0.293998</td>\n",
       "      <td>-0.127808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389135</td>\n",
       "      <td>0.168919</td>\n",
       "      <td>0.072802</td>\n",
       "      <td>0.042755</td>\n",
       "      <td>0.458136</td>\n",
       "      <td>0.238732</td>\n",
       "      <td>0.229641</td>\n",
       "      <td>-0.190284</td>\n",
       "      <td>0.120561</td>\n",
       "      <td>0.010098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2509</th>\n",
       "      <td>-0.190371</td>\n",
       "      <td>0.158153</td>\n",
       "      <td>0.088873</td>\n",
       "      <td>0.092478</td>\n",
       "      <td>0.097428</td>\n",
       "      <td>-0.538097</td>\n",
       "      <td>0.149127</td>\n",
       "      <td>0.502132</td>\n",
       "      <td>-0.274447</td>\n",
       "      <td>-0.119062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346429</td>\n",
       "      <td>0.168213</td>\n",
       "      <td>0.077290</td>\n",
       "      <td>0.020860</td>\n",
       "      <td>0.461935</td>\n",
       "      <td>0.198700</td>\n",
       "      <td>0.200154</td>\n",
       "      <td>-0.174497</td>\n",
       "      <td>0.148450</td>\n",
       "      <td>0.008869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>-0.252700</td>\n",
       "      <td>0.190297</td>\n",
       "      <td>0.117706</td>\n",
       "      <td>0.112766</td>\n",
       "      <td>0.127885</td>\n",
       "      <td>-0.672676</td>\n",
       "      <td>0.180623</td>\n",
       "      <td>0.625596</td>\n",
       "      <td>-0.341050</td>\n",
       "      <td>-0.154518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443120</td>\n",
       "      <td>0.207461</td>\n",
       "      <td>0.096214</td>\n",
       "      <td>0.028234</td>\n",
       "      <td>0.568651</td>\n",
       "      <td>0.250724</td>\n",
       "      <td>0.251985</td>\n",
       "      <td>-0.228703</td>\n",
       "      <td>0.176215</td>\n",
       "      <td>0.019859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>-0.230341</td>\n",
       "      <td>0.177645</td>\n",
       "      <td>0.109295</td>\n",
       "      <td>0.127031</td>\n",
       "      <td>0.112223</td>\n",
       "      <td>-0.627240</td>\n",
       "      <td>0.158965</td>\n",
       "      <td>0.557036</td>\n",
       "      <td>-0.317636</td>\n",
       "      <td>-0.149579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386982</td>\n",
       "      <td>0.194045</td>\n",
       "      <td>0.086125</td>\n",
       "      <td>0.014686</td>\n",
       "      <td>0.516601</td>\n",
       "      <td>0.205334</td>\n",
       "      <td>0.170706</td>\n",
       "      <td>-0.231239</td>\n",
       "      <td>0.185476</td>\n",
       "      <td>0.032180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>-0.222548</td>\n",
       "      <td>0.178217</td>\n",
       "      <td>0.100847</td>\n",
       "      <td>0.105852</td>\n",
       "      <td>0.105742</td>\n",
       "      <td>-0.621960</td>\n",
       "      <td>0.170569</td>\n",
       "      <td>0.577343</td>\n",
       "      <td>-0.311346</td>\n",
       "      <td>-0.141219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403997</td>\n",
       "      <td>0.195869</td>\n",
       "      <td>0.088569</td>\n",
       "      <td>0.018641</td>\n",
       "      <td>0.527501</td>\n",
       "      <td>0.223433</td>\n",
       "      <td>0.223891</td>\n",
       "      <td>-0.204896</td>\n",
       "      <td>0.166158</td>\n",
       "      <td>0.010368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "4869 -0.221435  0.147823  0.100683  0.074971  0.131486 -0.566019  0.141018   \n",
       "2509 -0.190371  0.158153  0.088873  0.092478  0.097428 -0.538097  0.149127   \n",
       "53   -0.252700  0.190297  0.117706  0.112766  0.127885 -0.672676  0.180623   \n",
       "2804 -0.230341  0.177645  0.109295  0.127031  0.112223 -0.627240  0.158965   \n",
       "2891 -0.222548  0.178217  0.100847  0.105852  0.105742 -0.621960  0.170569   \n",
       "\n",
       "            7         8         9   ...        90        91        92  \\\n",
       "4869  0.539932 -0.293998 -0.127808  ...  0.389135  0.168919  0.072802   \n",
       "2509  0.502132 -0.274447 -0.119062  ...  0.346429  0.168213  0.077290   \n",
       "53    0.625596 -0.341050 -0.154518  ...  0.443120  0.207461  0.096214   \n",
       "2804  0.557036 -0.317636 -0.149579  ...  0.386982  0.194045  0.086125   \n",
       "2891  0.577343 -0.311346 -0.141219  ...  0.403997  0.195869  0.088569   \n",
       "\n",
       "            93        94        95        96        97        98        99  \n",
       "4869  0.042755  0.458136  0.238732  0.229641 -0.190284  0.120561  0.010098  \n",
       "2509  0.020860  0.461935  0.198700  0.200154 -0.174497  0.148450  0.008869  \n",
       "53    0.028234  0.568651  0.250724  0.251985 -0.228703  0.176215  0.019859  \n",
       "2804  0.014686  0.516601  0.205334  0.170706 -0.231239  0.185476  0.032180  \n",
       "2891  0.018641  0.527501  0.223433  0.223891 -0.204896  0.166158  0.010368  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5d18c32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4869    0\n",
       "2509    0\n",
       "53      0\n",
       "2804    0\n",
       "2891    0\n",
       "       ..\n",
       "3511    0\n",
       "615     0\n",
       "681     0\n",
       "5328    0\n",
       "4205    0\n",
       "Name: Output, Length: 4455, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dcd306d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier= RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "82a3b941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9e474554",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3062bc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      ": [[957  17]\n",
      " [ 19 121]]\n",
      " Accuracy : 0.9676840215439856\n",
      " Precision : 0.8768115942028986\n",
      " Recall : 0.8642857142857143\n",
      " F1 Score : 0.8705035971223022\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "confusion_mtx = confusion_matrix(y_test, y_pred)\n",
    "print(f\"confusion matrix\\n: {confusion_mtx}\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\" Accuracy : {accuracy}\")\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f\" Precision : {precision}\")\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f\" Recall : {recall}\")\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\" F1 Score : {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "76e89289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       974\n",
      "           1       0.88      0.86      0.87       140\n",
      "\n",
      "    accuracy                           0.97      1114\n",
      "   macro avg       0.93      0.92      0.93      1114\n",
      "weighted avg       0.97      0.97      0.97      1114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e80f4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
